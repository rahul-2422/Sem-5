{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = pd.read_csv('descriptions.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["raw_text= data[['title', 'description']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["raw_text"]},{"cell_type":"markdown","metadata":{},"source":["Stage 1 : Data Pre-Processing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def to_remove_sq_brackets(sent):\n","    sent = re.sub(\"\\[|\\]\",\"\",sent) \n","    return sent"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clean_sentences = []\n","\n","for sent in raw_text['description']:\n","    clean_sentences.append(to_remove_sq_brackets(sent))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lower_text = []\n","\n","\n","for sent in clean_sentences:\n","    lower_text.append(str.lower(sent))"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lower_text"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from nltk.tokenize import sent_tokenize, word_tokenize\n","\n","import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tokens = [ word_tokenize(i) for i in lower_text ]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tokens"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clean_text = []\n","\n","for words in tokens: \n","    clean = []\n","    for w in words: \n","        res = re.sub(r'[^\\w\\s]',\"\", w)\n","        if res != \"\":\n","            clean.append(res)\n","        clean_text.append(clean)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clean_text"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from nltk.corpus import stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["stopword_removed = []\n","\n","for words in clean_text: \n","    w = []\n","    for word in words: \n","        if not word in stopwords.words('english'):\n","            w.append(word)\n","        stopword_removed.append(w)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["stopword_removed"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"6eb1ca0e59ab85dc9eb8be3744d92e9e4e7eb514696998a8a0ffac57ba5d31d3"}}},"nbformat":4,"nbformat_minor":2}
